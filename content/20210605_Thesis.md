Title: Simulation study to study SUBiNN model
Date: 2021-06-05 11:14
Tags: SUBINN, Simulation study, Power
Slug: simulation-study
Authors: Mariska van Willigen
Summary: A Simulation Study toInvestigate the Feature SelectionPerformance of a Stacked Uni-and Bivariate Nearest NeighborsClassifier

## Simulation study to study SUBiNN model

SUBiNN is a Stacked Uni- and Bivariate Nearest Neighbors classifier with kNN
classifiers as base-learners and a Lasso feature selection as meta-learner. The
aim of this present research is to estimate the power, type I error and the false
discovery rate of the SUBiNN model to find interactions and main effects in
the data. 

See my previous post for more information about the SUBiNN model [Click here!](https://mariskavanwilligen.github.io/subinn-model.html)

## Simulation study set-up

This simulation study makes use of a full factorial 3-by-3-by-2 design
where systematically varied sample sizes and effect sizes are used in the data
generating process. Additionally, varied number of neighbors k are used in the
kNN classifiers.

![](/images/Thesis/Thesis4b.png)

For each of the 100 replications, SUBiNN is fitted to a data set
with 10 uniformly distributed features with one main effect and two interaction
effects. The power, type I error and false discovery rate will be estimated to
measure the feature selection performance in every condition. The stability of
the results is examined in a follow-up study with one data set.

![](/images/Thesis/Thesis6.png)

# Data generation process

![](/images/Thesis/Thesis5.png)

![](/images/Thesis/Thesis13.png)


## Results & Conclusion

![](/images/Thesis/Thesis14.png)

![](/images/Thesis/Thesis12.png)

The results of this simulation study show that a bigger effect size and sample
size leads to an increased ability to identify the interaction and main effects.
Furthermore, the different values of neighbors did not have a significant impact on the power. Although, the number of neighbors did have an impact
on the type I error, a higher number of neighbors will result in a lower type
I error. In all the conditions, the false discovery rates are quite high, mean-
ing that of all the selected base-learners, there are still a few uninformative
base-learners selected. From the follow-up study it can be concluded that 10-
fold cross-validation caused unstable results when no repeated cross-validation
is performed. Based on this simulation study and the follow-up study, it is
strongly recommended to have a sample size of at least 500 and the number
of neighbors set to 10 or the square root of N with repeated cross-validation to identify main
effects and interactions with a SUBiNN model.



