Title: Scaling Options Azure Kubernetes Service (AKS)
Date: 2022-04-05 10:43
Tags: Azure, Kubernetes, Scaling, Pods, AKS, Instances
Slug: 
Authors: Mariska van Willigen
Summary: Overview of the different scaling options in Azure Kubernetes Service

## Scaling in AKS
Running an Azure Kubernetes Service (AKS) could lead to wanting increase or decrease the amount of your compute resources. If you change the instances, you might also want to change the underlying Kubernetes nodes.

You have different scale options:

1. Manually scaling
2. Horizontal scaling
3. Cluster autoscaler
4. Azure Container Instance integration

## Manually scaling
You can manually change the used replicas/pods and nodes to test the effect on your application. Here you can also define a fixed number of nodes to keep a fixed cost. To do this, you need to define the replica or node count. The Kubernetes API will then create these pods and nodes based on your count.

## Understanding horizontal pod autoscalers
Horizontal scaling checksby default every 60 seconds the demand on the app. If changes in the number of instances are required, Kubernetes will increase the replicas/instances. 
When the requirements are decreasing, the number of pods will also decrease.

You do have to define a min and a max number of replicas that can run and a metric such as CPU usage that needs to be checked every 60 seconds to determine the increase or decrease of the replicas.

![](/images/horizontal-pod-autoscaling.png)

You can also set a delay value. This value is defines how long the horizontal pod autoscaler must wait after it has scaled up or down the number of replicas. This makes sure that earlier scaling is taken into account during the metric check. 
This delay value on scale down event is by default set to 5 minutes. Currently, you can't tune these cooldown values from the default.

## Example
You can set the min replicas and the maximum replicas you would ike. If the average CPU utilization across all pods exceeds 55% of their requested usages, the autoscaler increases the pods up to a maximum of 10 instances.
If there is a minimum load for a few minutes on the app, the number of pods will decrease automatically to the min of 3. 

Below you can find the manifest file yaml with the defined autoscaler and resource limits:
``` sh
apiVersion: autoscaling/v1
kind: HorizontalPodAutoscaler
metadata:
  name: {{ environ('APP_NAME') }}
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: {{ environ('APP_NAME') }}
  minReplicas: 3
  maxReplicas: 10
  targetCPUUtilizationPercentage: 55
```

Then run the following:
```js
kubectl apply -f filename.yaml
```

You can also do this by running a kubectl command:
```js
kubectl autoscale deployment {{ environ('APP_NAME') }} --cpu-percent=50 --min=3 --max=10
```
## Cluster Autoscaler

The horizontal pod autoscaler can increase or decrease the number of replicas/instances/pods. However, the cluster autoscaler can adjust the number of nodes based on the requested compute resources in the node pool. By default the cluster autoscaler checks the Metrics API server every 10 seconds. If a change is necessary the number of nodes in your AKS cluster is increased or decreased. 

![](/images/cluster-autoscaler.png)

When the cluster autoscaler sees that no new request can't be handeled because of node pool resource constraints, the number of nodes within the node pool will be increased to provide the additional compute resources. When those additional nodes are successfully deployed and available for use within the node pool, the pods are then scheduled to run on them.

The cluster autoscaler also monitors the pod status for nodes that haven't handeled any new requests. This indicates that the node pool has more compute resources than are necessary, so the number of nodes can be decreased.

## Azure Container Instances
If you need a very quick response and quickly deplot container instances without additional infrastructure overhad you can use Azure Container Instances. 

![](/images/burst-scaling.png)
