Title: MLflow Introduction
Date: 2021-04-23 10:20
Tags: MLflow, tracking, introduction
Slug: mlflow
Authors: Mariska van Willigen
Summary: A short introduction to MLflow tracking


## What is MLflow & MLflow tracking?

[MLFlow](https://www.mlflow.org/) is the open-source solution for both the data scientist and the dev-ops engineer to track and register your models. You can divide MLFlow in MLFlow tracking part and a MLFlow modeling and model register part. This post will focuss on the MLFlow Tracking part and how it can be used. MLFlow tracking allows you to organize your data science artifacts into experiments and runs within your experiment.

![](/images/mlflow.png)

With MLflow you can keep track of all kind of information, for example your parameters used in your model. Each run a new line/row will created in your experiment. You can store anything you want in a given run, and it does not need to match exactly to the last run.

The following options you can use to record (log) information to MLFlow:

> **log_param**: Allows you to log any model/pipeline parameters you’d like. Think train/test split, hyperparameters, stages of a transformation pipeline, a description of a specific source dataset.
>
> **log_params**: MLManager specific function that takes a list of parameters to log and handles them all automatically
>
> **log_metric**: Allows you to log any model metrics. Think train time, accuracy, precision, AUC etc.
>
> **log_metrics**: MLManager specific function that takes a list of metrics and handles them all automatically
>
> **log_artifact**: Allows you to log objects to a specific run. Think charts, serialized models, images etc.
>
> **log_artifacts**: MLManager specific function that takes a list of artifacts and handles them all
>
> **log_feature_transformation**: MLManager specific function that takes an **untrained** Spark Pipeline and logs all of the transformation steps of every feature in your dataset
>
> **log_pipeline_stages**: MLManager specific function that takes a Spark Pipeline (fit or unfit) and logs all of the stages in a readable format
>
> **log_model_params**: MLManager specific function that takes a fitted Spark model or Pipeline model and logs all of the parameters and hyperparameters
>
> **log_evaluator_metrics**: MLManager specific function that takes a Splice Evaluator and logs all of its metrics
>
> **log_spark_model**: MLManager specific function that takes a trained Spark model and logs it for deployment. This was created because, with Splice Machine’s implementation, the model is stored directly in the Splice Machine database instead of S3 or in external storage.